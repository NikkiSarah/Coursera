General approaches to optimisation
- there can be a discrepancy between the target metric and the loss function the model is optimising
- various approaches to mitigate this:
	- use the right model
	- proprocess the training date and optimise a different metric
	- optimise a different metric and post-process the predictions
	- write a custom loss function
	- optimise another metric using early stopping


Regression metrics review
- MAE vs MSE
	- MAE is more robust than MSE i.e. it is less sensitive to outliers
	- use MSE if they are unexpected values that are rare but still valid
	- MSW, RMSE and R^2 are the same from an optimisation perspective


Regression metric optimisation
- MSE and MAE
	- very common and implemented in many packages
- RMSPE and MAPE
	- resample the training data OR set proper sample weights
- RMSLE
	- optimise MSE in the logarithmic space


Classification metrics
- Accuracy
	- essential metric
	- simple model predicting the same value all the time could have a very high accuracy
	- score also depends on the threshold chosen to convert class probabilities to hard labels
- Logloss
	- depends on class probabilities rather than hard labels
- AUC
	- doesn't depend on the absolute values predicted by the classifiers
	- only considers object ordering
	- also implicitly tries all the thresholds to converge soft predictions to hard labels and thus removes the dependence of the score on the chosen threshold
- Cohen's Kappa
	- fixes the baseline for accuracy score to be zero
	- in spirit, very similar to how R^2 scales MSE value to be more easily explained
	- weighted Kappa with quadratic weights is sometimes called quadratic weighted kappa and is commonly used on Kaggle


Classification metric optimisation
- Logloss
