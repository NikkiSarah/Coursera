{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13da362d-ae03-49b8-a305-1feb3c83662d",
   "metadata": {},
   "source": [
    "# Topic Classification Using Unsupervised and Supervised Approaches\n",
    "This assignment compares how well unsupervised matrix factorisation and two supervised learning models classify [BBC News data](https://www.kaggle.com/competitions/learn-ai-bbc/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893c1974-9961-44df-9c2c-8d7ad3229b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the seaborn FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73753124-dfac-488d-84fb-4fd9bc9a7644",
   "metadata": {},
   "source": [
    "## Task 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73aae8c8-b991-434b-9ea1-b1881370d9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "train = pd.read_csv('./inputs/learn-ai-bbc/BBC News Train.csv')\n",
    "test = pd.read_csv('./inputs/learn-ai-bbc/BBC News Test.csv')\n",
    "\n",
    "# take a look at the first few rows of each dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dade0e27-1ca8-4495-99e5-75f1ec416223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text\n",
       "0       1018  qpr keeper day heads for preston queens park r...\n",
       "1       1319  software watching while you work software that...\n",
       "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
       "3        459  india s reliance family feud heats up the ongo...\n",
       "4       1020  boro suffer morrison injury blow middlesbrough..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe238dc-ed45-4976-bb3d-87715976b80e",
   "metadata": {},
   "source": [
    "Notice that the test dataset doesn't include labels, so it couldn't be used directly for model performance evaluation. Instead this was done fully on the training dataset. Also, note that all the text is already in lower-case, which means it didn't have to be included in the data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0020114-c715-427c-91c9-3435b6ee59dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check out the distribution of category labels\n",
    "sns.countplot(data=train, x=\"Category\", color=\"seagreen\")\n",
    "plt.title(\"Distribution of articles by category\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c59b7f-f08b-4739-8695-0e223fe78c50",
   "metadata": {},
   "source": [
    "The distribution is fairly even, which was good for the supervised component of this analysis as classification algorithms typically have a tendency to focus on the majority class without some adjustment (resampling, changing weights etc). However, business and sports articles are slightly more common than tech, politics or entertainment articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5900ce-dfa0-44dc-b474-d91fc403694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the number of tokens in the articles\n",
    "train['NumChars'] = train.Text.apply(lambda x: len(x))\n",
    "train['NumWords'] = train.Text.apply(lambda x: len(x.split()))\n",
    "\n",
    "train.groupby('Category')['NumWords'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5411a-1172-4444-ba0c-93483b900696",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "sns.boxplot(data=train, x=\"Category\", y=\"NumWords\", showfliers=False, color=\"seagreen\", ax=axs[0])\n",
    "plt.title(\"Distribution of word counts by category\")\n",
    "sns.despine()\n",
    "\n",
    "sns.histplot(data=train, x=\"NumWords\", hue=\"Category\", color=\"seagreen\", multiple=\"stack\", palette=\"Greens\", ax=axs[1])\n",
    "plt.title(\"Distribution of word counts by category\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f44b3b-4beb-4f62-b0bd-4ed8a8a03915",
   "metadata": {},
   "source": [
    "Tech and politics articles tended to have the largest number of words per article, but the distributions by category are faily similar; that is, there are more shorter articles and a relatively long right tail to all the distributions with a couple of significant outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ca0fe-56a4-4c35-aa97-828103c29d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the english spacy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "t0 = time()\n",
    "# apply the spacy model to the training data\n",
    "processed_docs = [nlp(text) for text in train.Text]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ac611-6691-4cd2-b60f-567c728fac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract noun chunks\n",
    "doc_noun_phrases = []\n",
    "doc_noun_phrases_joined = []\n",
    "for doc in processed_docs:\n",
    "    phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    phrases2 = [phrase.replace(\" \", \"_\") for phrase in phrases]\n",
    "    doc_noun_phrases.append(phrases)\n",
    "    doc_noun_phrases_joined.append(phrases2)\n",
    "# noun_phrases = [phrases for doc in doc_noun_phrases for phrases in doc]\n",
    "# noun_phrases_joined = [phrases for doc in doc_noun_phrases_joined for phrases in doc]\n",
    "train['NounPhrases'] = doc_noun_phrases\n",
    "train['NounPhrasesJoined'] = doc_noun_phrases_joined\n",
    "\n",
    "# create a version without single words\n",
    "doc_noun_phrases = []\n",
    "doc_noun_phrases_joined = []\n",
    "for doc in train.NounPhrases:\n",
    "    # lengths = [len(token.split()) for token in doc]\n",
    "    phrases = [token for token in doc if len(token.split()) > 1]\n",
    "    phrases2 = [phrase.replace(\" \", \"_\") for phrase in phrases]\n",
    "    doc_noun_phrases.append(phrases)\n",
    "    doc_noun_phrases_joined.append(phrases2)\n",
    "train['NounPhrasesSub'] = doc_noun_phrases\n",
    "train['NounPhrasesJoinedSub'] = doc_noun_phrases_joined\n",
    "\n",
    "# convert list to strings\n",
    "train['NounStrings'] = train.NounPhrasesJoined.apply(lambda x: \" \".join(x))\n",
    "train['NounStringsSub'] = train.NounPhrasesJoinedSub.apply(lambda x: \" \".join(x))\n",
    "\n",
    "# create a colour map dictionary and convert the RGB tuples to hexidecimal\n",
    "color_dict = {'business': sns.color_palette(\"crest\")[0],\n",
    "              'entertainment': sns.color_palette(\"crest\")[1],\n",
    "              'politics': sns.color_palette(\"crest\")[2],\n",
    "              'sport': sns.color_palette(\"crest\")[3],\n",
    "              'tech': sns.color_palette(\"crest\")[4]}\n",
    "\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255))\n",
    "\n",
    "color_dict = {category: rgb_to_hex(rgb) for category, rgb in color_dict.items()}\n",
    "\n",
    "# group and join the phrases from each category\n",
    "grouped_train_sub = train.groupby('Category')['NounStringsSub'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "grouped_train = train.groupby('Category')['NounStrings'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "# plot a grid of word clouds\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15,10))\n",
    "for idx, (ax, (category, row)) in enumerate(zip(axs.flatten(), grouped_train_sub.iterrows())):\n",
    "    category = row['Category']\n",
    "    phrases = row['NounStringsSub']\n",
    "\n",
    "    wc = WordCloud(color_func=lambda *args, **kwargs: color_dict[category])\n",
    "    wc.generate(phrases)\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f'{category}', fontsize=12)\n",
    "fig.suptitle('Noun Phrase Word Clouds by Category')\n",
    "# remove the last empty plot\n",
    "fig.delaxes(axs.flatten()[-1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311abc3a-2f95-40ca-b20f-2311470d1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15,10))\n",
    "for idx, (ax, (category, row)) in enumerate(zip(axs.flatten(), grouped_train.iterrows())):\n",
    "    category = row['Category']\n",
    "    phrases = row['NounStrings']\n",
    "\n",
    "    wc = WordCloud(color_func=lambda *args, **kwargs: color_dict[category])\n",
    "    wc.generate(phrases)\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f'{category}', fontsize=12)\n",
    "fig.suptitle('Noun Phrase Word Clouds by Category')\n",
    "# remove the last empty plot\n",
    "fig.delaxes(axs.flatten()[-1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ddcde-41de-45a3-abf4-e24410b5b8fb",
   "metadata": {},
   "source": [
    "The first word cloud excluded unigrams, and the second set left them in. Either way, they are both consistent and even without the headings, it would be reasonably clear what the different categories were about: 'business' mentions things like markets, companies, the economy; 'entertainment' mentions films, shows and awards; 'politics' is very UK-specific with things the tories and Tony Blair; 'sport' mentions games, matches and players; and 'tech' mentions things like technology, service, internet and names of countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abbaad-45f9-48b9-ad7c-d73260e289fb",
   "metadata": {},
   "source": [
    "## Task 2: Data Pre-Processing\n",
    "\n",
    "The pre-processing for text data is typically slightly different to how it would be approached for a regular tabulardataset. Specifically, it needs to be essentially converted into a numeric representation that a machine can understand. Techniques employed to do this include things like converting all text into a single case (usually lower-case), splitting text into individual words (tokenising), removing extraneous information like punctuation, numbers and symbols, and 'noise' words that provide next-to-no extra information (stopwords). However, more modern approaches using Large Language Models for example, often use this information to provide extra context, so whilst they may still tokenise the text, the removal of certain tokens may not occur. In addition, there is other processing like padding out each tokenised string to the same length and adding a mask to differentiate between the content and the padding.\n",
    "\n",
    "This analysis used a more classical text pre-processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287adf53-77df-4d43-9585-69295f2a25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(data_series, alphanumeric_tokens = True, single_tokens = False):\n",
    "    # apply the spacy model to the input text data\n",
    "    processed_docs = [nlp(text) for text in data_series]\n",
    "\n",
    "    clean_docs = []\n",
    "    clean_text = []\n",
    "    for doc in processed_docs:\n",
    "        if alphanumeric_tokens == True:\n",
    "            if single_tokens == False:\n",
    "                clean_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and\n",
    "                                token.is_alpha and len(token) > 1]\n",
    "            else:\n",
    "                clean_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and\n",
    "                                token.is_alpha]\n",
    "        else:\n",
    "            if single_tokens == False:\n",
    "                clean_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and\n",
    "                                len(token) > 1]\n",
    "            else:\n",
    "                clean_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        clean_docs.append(clean_tokens)\n",
    "\n",
    "        clean_strings = ' '.join(clean_tokens)\n",
    "        clean_text.append(clean_strings)\n",
    "\n",
    "    return clean_docs, clean_text\n",
    "\n",
    "# convert list to strings\n",
    "t0 = time()\n",
    "clean_docs, clean_text = process_text(train.Text)\n",
    "train['CleanTokens'] = clean_docs\n",
    "train['CleanText'] = clean_text\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1c3b1-f231-4e3c-ac37-278a32075fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of the original text\n",
    "doc_idx = 1489\n",
    "train.Text[doc_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d9028-0479-4bbc-910b-69bdcf92b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same example but pre-processed\n",
    "train.CleanText[doc_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0cafd-454a-43dc-9c2f-7b8c6cea1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CleanTokens[doc_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529d385-1514-4faa-b646-09ee09465002",
   "metadata": {},
   "source": [
    "## Task 3: Feature Extraction\n",
    "\n",
    "As mentioned previously, computers don't understand text and need it to be converted into a numeric representation before it can be input into a machine learning algorithm. One of the simplest approach is 'Bag of Words', which represents each document as the count of each token in the entire dataset, where a token could be a single word and/or a longer n-gram. One slight variation on this idea is to weight tokens by how frequently they appear in a particular documents by how many documents in the datasets they are in. The idea behind the approach is two-fold: firstly, more important terms should receive a words that are less important. Secondly, a term should be considered more important if it appears frequently in a subset of the documents, and less important if it either appears infrequently or appears frequently across every document. The formal name for the approach is Term Frequency-Inverse Document Frequency or TF-IDF vectorisation, and is the text feature generation approach that will be used for the analysis.\n",
    "\n",
    "In addition, the EDA indicated that there were some very long articles in the dataset. These were removed in case the algorithm mistakenly used the length of the articles to infer something about how they should be categorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854470d6-f2e4-4539-9d31-c3775082b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove articles in the top 1%\n",
    "top = np.quantile(train.NumWords, q=0.99)\n",
    "train_sub = train.loc[train.NumWords < top]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a154876-0af3-42c9-a21c-191338233d4f",
   "metadata": {},
   "source": [
    "The effect of removing the top 1% of articles was almost nill on the mean and median word count, but brought the maximum down significantly (from 3,345 words to 464)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b5f71-6490-4f43-8207-99633588b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tfidf vectoriser with default arguments (extracts single word tokens, doesn't remove stopwords, expects\n",
    "# strings, use all features etc)\n",
    "train_vec = TfidfVectorizer()\n",
    "train_mat = train_vec.fit_transform(train_sub.CleanText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1fe61b-e75a-4bcf-ad7b-2ded019dad35",
   "metadata": {},
   "source": [
    "## Task 4: Unsupervised Learning - Matrix Factorisation\n",
    "\n",
    "When you train the unsupervised model for matrix factorisation, should you include texts (word features) from the test dataset or not as the input matrix? Why or why not?\n",
    "\n",
    "Text / word features from the test set should be included in the input matrix as there may be features in the test set only. If the model comes across new features it hasn't seen before during model training then it won't know how to handle them. This isn't technically classified as data leakage as the ground truth labels aren't being used to help the model learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d128d81-18c1-4d6b-8f53-f96f0cbda4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the train and test datasets together to build a Tf-Idf matrix with the entire vocabulary\n",
    "train_test = pd.concat([train[['ArticleId', 'Category', 'Text']], test[['ArticleId', 'Text']]])\n",
    "# count the number of words in each article and remove the top 1%\n",
    "train_test['NumWords'] = train_test.Text.apply(lambda x: len(x.split()))\n",
    "train_test.NumWords.describe()\n",
    "train_test_sub = train_test.loc[train_test.NumWords < top]\n",
    "# again has very little impact on the mean/median, but removes all the very long outlying articles\n",
    "train_test_sub.NumWords.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482e477-0738-4e7b-be03-3e74d6e55acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the raw strings\n",
    "t0 = time()\n",
    "_, clean_text = process_text(train_test_sub.Text)\n",
    "train_test_sub.loc[:, 'CleanText'] = clean_text\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb53d4-8e5d-44f8-b8b2-366f6d30d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the default parameters for now (we'll play with them later)\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "# apply the vectoriser to the combined dataset\n",
    "train_test_mat = tfidf_vec.fit_transform(train_test_sub.CleanText)\n",
    "# get the vocab (this is important for identifying the top terms in a topic)\n",
    "vocab = np.array(tfidf_vec.get_feature_names_out())\n",
    "# vocab = tfidf_vec.vocabulary_  # this is a dictionary representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3da770-bbad-4dc7-96ca-0a350795c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b653fc0-ca96-4276-9645-d43c11844a4d",
   "metadata": {},
   "source": [
    "There are 21,389 tokens across 2,202 articles. To reduce the number of terms in the vocabulary, terms that only appear in 1 article and/or 95% of articles could be filtered out for example. Note that the number of features in the matrix is the same as the number of terms in the vocabulary.\n",
    "\n",
    "sklearn's implementation of non-negative matrix factorisation (NMF) was used to extract the topic structure. NMF decomposes a document feature matrix into two component matrices that are iteratively adjusted until the difference between the original matrix and the product of these component matrices is minimised. What this means for text classification is that each document is represented as a linear combination of topics, and then each document is given the label of the most representative topic. Other matrix factorisation methods include latent semantic analysis (TruncatedSVD in sklearn) or Latent Dirichlet Allocation. Whilst LDA is a popular algorithm, NMF can sometimes produce more coherent topics. The choice of algorithm for this analysis was largely random and the author wanted to try something other than the popular LDA and LSA approaches.\n",
    "\n",
    "Recall that the idea of NMF is to extract an additive model of the topic structure of the corpus. The output is a list of topics, with each topic represented by a list of terms (words in this case). The dimensionality of the problem and hence the runtime can be controlled by the number of documents, number of topics (n_components) and the number of features in the vectoriser (max_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38060fca-db36-4965-bfdb-10ee6b86abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that there are 5 topics, so we can explicitly specify this\n",
    "nmf_init = NMF(n_components=5, init='nndsvd', random_state=42)\n",
    "# extract the component matrices\n",
    "nmf_W1_document_topics = nmf_init.fit_transform(train_test_mat)\n",
    "nmf_H1_topic_terms = nmf_init.components_\n",
    "\n",
    "# take a look at the top terms from each topic and map them to the known categories\n",
    "num_terms = 20\n",
    "topic_terms = pd.DataFrame(np.apply_along_axis(lambda x: vocab[(np.argsort(-x))[:num_terms]], 1, nmf_H1_topic_terms))\n",
    "topic_terms.reset_index(inplace=True)\n",
    "topic_terms.rename(columns={'index': 'Category'}, inplace=True)\n",
    "topic_dict = {0: 'sport', 1: 'politics', 2: 'tech', 3: 'entertainment', 4: 'business'}\n",
    "topic_terms['Category'] = topic_terms.Category.map(topic_dict)\n",
    "topic_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0015c0d-24dd-43e5-8086-61289442eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict the labels of the train and test set\n",
    "def generate_predictions(vectoriser, df, text_col, model, label_col, topic_dict):\n",
    "    vectors = np.array(vectoriser.transform(df[text_col]).todense())\n",
    "    preds = model.transform(vectors)\n",
    "    pred_df = pd.DataFrame(np.argmax(preds, axis=1).reshape(-1, 1), columns=['Predicted'])\n",
    "    pred_df['PredictedLabel'] = pred_df.Predicted.map(topic_dict)\n",
    "    pred_df['ArticleId'] = df['ArticleId']\n",
    "\n",
    "    if label_col is None:\n",
    "        pass\n",
    "    else:\n",
    "        topic_dict_rev = {'sport': 0, 'politics': 1, 'tech': 2, 'entertainment': 3, 'business': 4}\n",
    "        pred_df['Actual'] = df[label_col].map(topic_dict_rev)\n",
    "        pred_df['ActualLabel'] = pred_df.Actual.map(topic_dict)\n",
    "\n",
    "    return pred_df\n",
    "\n",
    "train_preds = generate_predictions(tfidf_vec, train, 'CleanText', nmf_init, 'Category', topic_dict)\n",
    "\n",
    "# Calculate and display a confusion matrix and some accuracy metrics like F1 and accuracy\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, topic_dictionary):\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predicted_labels)\n",
    "    cm_df = pd.DataFrame(cm, columns=topic_dictionary, index=topic_dictionary)\n",
    "    # cm_df = pd.DataFrame(cm, columns=topic_dictionary, index=topic_dictionary)\n",
    "    ax = sns.heatmap(cm_df, annot=True, fmt=\".0f\", cbar=False, cmap=\"Greens\")\n",
    "    ax.set(xlabel=\"Predicted Label\", ylabel=\"True Label\",\n",
    "           title='Non-Negative Matrix Factorisation Training Data Confusion Matrix')\n",
    "\n",
    "plot_confusion_matrix(train_preds.Actual, train_preds.Predicted, list(topic_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c730a0-21d6-4e85-9ea5-c0bcf849896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(train_preds.Actual, train_preds.Predicted)\n",
    "print(\"Training data accuracy: %.4f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03682625-34fd-442b-b444-c858a5221c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(train_preds.Actual, train_preds.Predicted, average='weighted')\n",
    "print(\"Training data F1 score: %.4f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62afef-18ab-4df0-a8e4-bba8de5f44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test data\n",
    "t0 = time()\n",
    "_, clean_text = process_text(test.Text)\n",
    "test.loc[:, 'CleanText'] = clean_text\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3f5af-3c19-4a6d-b35e-93a0e0f5d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = generate_predictions(tfidf_vec, test, 'CleanText', nmf_init, None, topic_dict)\n",
    "kaggle_submission = test_preds.loc[:, ['ArticleId', 'PredictedLabel']]\n",
    "kaggle_submission.columns=['ArticleId', 'Category']\n",
    "kaggle_submission.to_csv('./outputs/kaggle submission nmf init.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd3dfe-7da0-45fe-8aa9-0ae0647dcfe4",
   "metadata": {},
   "source": [
    "It looks like the algorithm does pretty well. Accuracy is around 92% on the training data. The problem areas are mistaking business articles for politics and tech articles, and a little bit surprisingly, entertainment articles for tech articles. When submitted to the kaggle platform, accuracy increased slightly to around 93%, confirming that the model was already doing reasonably well out-of-the-box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e020fc25-9a38-4f9e-b478-a7f78a9cf663",
   "metadata": {},
   "source": [
    "## Task 5: Hyperparameter Tuning\n",
    "\n",
    "Coul it do even better? A grid search approach was used to test whether changing some of the hyperparameters improves performance. The hyperparameters included the initialisation method, the solver, the beta divergence method, W and H regularisation, and regularisation mixing. Additional parameters that weren't tuned included using higher-order n-grams instead of just words and including the very long articles as well.\n",
    "\n",
    "Note that this script was initially developed and run in a python IDE, so this cell hasn't been run from the notebook because it takes a very long time... up to 2,880 possible combinations! (1.58 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb4619-2a5d-413e-81e0-dea635fee35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training and development or validation set. It's best-practice when conducting\n",
    "# hyperparameter tuning to assess performance on unseen data without touching the actual test set.\n",
    "X = train.loc[:, ['ArticleId', 'Text', 'CleanTokens', 'CleanText']]\n",
    "y = train.Category\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# not entirely sure why I need to reset the indices to get the results to line up.\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_val.reset_index(drop=True, inplace=True)\n",
    "y_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "param_grid = {'init': ('nndsvd', 'nndsvda', 'nndsvdar', 'random'),\n",
    "              'solver': ('mu', 'cd'),\n",
    "              'beta_loss': ('kullback-leibler', 'frobenius'),\n",
    "              'alpha_W': [0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "              'alpha_H': ['same', 0, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    "              'l1_ratio': [0, 0.25, 0.5, 0.75, 1]}\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "param_list = []\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "\n",
    "for init, solver, loss, aW, aH, l1 in product(param_grid['init'], param_grid['solver'], param_grid['beta_loss'],\n",
    "                                              param_grid['alpha_W'], param_grid['alpha_H'], param_grid['l1_ratio']):\n",
    "    # combinations that I know don't work\n",
    "    if (solver == 'mu' and init == 'nndsvd') or (solver == 'cd' and loss == 'kullback-leibler') or \\\n",
    "        (solver == 'cd' and init in ['nndsvd', 'nndsvda'] and loss == 'frobenius' and aW > 0 and l1 > 0) or \\\n",
    "        (solver == 'cd' and init in ['nndsvd', 'nndsvda', 'nndsvdar'] and loss == 'frobenius' and aW == 0 and\n",
    "            (aH in [0.01, 0.1, 1]) and l1 > 0) or \\\n",
    "        (solver == 'mu' and init == 'nndsvda' and loss == 'frobenius' and aW > 0 and aH != 0 and l1 > 0) or \\\n",
    "        (init == 'nndsvdar' and loss == 'frobenius' and aW > 0 and aH != 0 and l1 > 0) or \\\n",
    "        (init == 'random'):\n",
    "        pass\n",
    "    else:\n",
    "        params = [init, solver, loss, aW, aH, l1]\n",
    "        nmf_tuned = NMF(n_components=5, init=init, solver=solver, beta_loss=loss, max_iter=1000, random_state=42,\n",
    "                        alpha_W=aW, alpha_H=aH, l1_ratio=l1)\n",
    "        nmf_tuned.fit(train_test_mat)\n",
    "        try:\n",
    "            # predict the training data labels\n",
    "            train_preds = generate_predictions(tfidf_vec, train, 'CleanText', nmf_tuned, 'Category', topic_dict)\n",
    "            # calculate the accuracy\n",
    "            train_acc = accuracy_score(train_preds['ActualLabel'], train_preds['PredictedLabel'])\n",
    "            train_f1 = f1_score(train_preds['ActualLabel'], train_preds['PredictedLabel'], average='weighted')\n",
    "\n",
    "            # print and save the results of the better combinations\n",
    "            if train_acc > 0.5:\n",
    "                print(params, round(train_acc, 4))\n",
    "\n",
    "                param_list.append(params)\n",
    "                acc_list.append(train_acc)\n",
    "                f1_list.append(train_f1)\n",
    "        # ValueError: Array passed to NMF (input H) is full of zeros.\n",
    "        except ValueError:\n",
    "            print(params, \"Error raised\")\n",
    "\n",
    "print(\"done in %0.3fh.\" % ((time() - t0)/60/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddfb94-c5f2-488e-afb0-806a94521a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data={'hyperparameters': param_list, 'accuracy_score': acc_list,\n",
    "                             'f1_score': f1_list})\n",
    "results.sort_values(by='accuracy_score', inplace=True, ascending=False)\n",
    "results.to_csv(\"./outputs/nmf tuning results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd28c8-f6e2-44d8-b190-0a5410b00690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best combination and retrain the model to predict the labels on the train and test set\n",
    "# it's nice to see there's no conflict between the best model based on accuracy vs F1\n",
    "best_params = results.head(1)\n",
    "best_params_f1 = results.sort_values(by='f1_score', ascending=False).head(1)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf15a2-43b7-4c6c-b61f-763a23e66391",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_final = NMF(n_components=5, init='nndsvda', solver='mu', beta_loss='kullback-leibler', max_iter=500,\n",
    "                random_state=42, alpha_W=1, alpha_H=0.1, l1_ratio=0)\n",
    "nmf_final.fit(train_test_mat)\n",
    "\n",
    "train_preds = generate_predictions(tfidf_vec, train, 'CleanText', nmf_final, 'Category', topic_dict)\n",
    "test_preds = generate_predictions(tfidf_vec, test, 'CleanText', nmf_final, None, topic_dict)\n",
    "\n",
    "kaggle_submission = test_preds.loc[:, ['ArticleId', 'PredictedLabel']]\n",
    "kaggle_submission.columns=['ArticleId', 'Category']\n",
    "kaggle_submission.to_csv('./outputs/kaggle submission nmf final.csv', index=False)\n",
    "\n",
    "plot_confusion_matrix(train_preds.Actual, train_preds.Predicted, list(topic_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640740a-76d9-489a-8c76-fba0baf64c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(train_preds.Actual, train_preds.Predicted)\n",
    "print(\"Training data accuracy: %.4f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a399d-6ba5-4a47-9d1e-5623a6e357e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(train_preds.Actual, train_preds.Predicted, average='weighted')\n",
    "print(\"Training data F1 score: %.4f\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec4f7c-fe08-4611-b00a-e28ad3a68e35",
   "metadata": {},
   "source": [
    "It looks as though the tuning has worked and model accuracy has improved to around 94% on the training data. The algorithm was more sucessful at correctly classifying entertainment articles (recall the initial model liked to classify them as tech articles), but was still missclassifying business articles as either politics or tech articles. When submitted to the kaggle platform, accuracy also increased slightly to around 93%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05223c3a-b884-4949-a895-2a33a64d7903",
   "metadata": {},
   "source": [
    "## Task 6a: Supervised Learning Model 1 - Spacy\n",
    "\n",
    "The first supervised learning algorithm used to classify the news articles is Spacy's text categoriser ('textcat').\n",
    "\n",
    "There are 3 architectures available:\n",
    "- Stacked ensemble of a linear BoW and neural network model. The neural network is built on top of a Tok2Vec (token to vector) layer and uses attention. This is the default architecture.\n",
    "- Neural network model where token vectors are calculated using a CNN. According to the documentation, it's typically less accurate than the default but faster.\n",
    "- n-gram BoW model. Runs the fastest, but has particular trouble with short texts (Not too much of an issue in this case, but could be if analysing customer feedback for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09414f63-81b8-4005-b5de-a8385e7f9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the english spacy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ca6923-e7e3-42c8-a834-5fe2bb10a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'textcat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if textcat is part of the pipeline\n",
    "if nlp.has_pipe(\"textcat\"):\n",
    "    pass\n",
    "else:\n",
    "    textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "print(nlp.pipe_names)\n",
    "# add the labels (categories) to the pipeline component\n",
    "textcat.add_label(\"business\")\n",
    "textcat.add_label(\"entertainment\")\n",
    "textcat.add_label(\"politics\")\n",
    "textcat.add_label(\"sports\")\n",
    "textcat.add_label(\"tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b614f7-4847-44fe-a2a2-d0912a3bf81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('business', 'entertainment', 'politics', 'sports', 'tech')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double-check they've been added\n",
    "textcat.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8a050f-4d7f-4436-bc8a-bb860b536bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.0,\n",
       " 'model': {'@architectures': 'spacy.TextCatEnsemble.v2',\n",
       "  'linear_model': {'@architectures': 'spacy.TextCatBOW.v2',\n",
       "   'exclusive_classes': True,\n",
       "   'ngram_size': 1,\n",
       "   'no_output_layer': False},\n",
       "  'tok2vec': {'@architectures': 'spacy.Tok2Vec.v2',\n",
       "   'embed': {'@architectures': 'spacy.MultiHashEmbed.v2',\n",
       "    'width': 64,\n",
       "    'rows': [2000, 2000, 500, 1000, 500],\n",
       "    'attrs': ['NORM', 'LOWER', 'PREFIX', 'SUFFIX', 'SHAPE'],\n",
       "    'include_static_vectors': False},\n",
       "   'encode': {'@architectures': 'spacy.MaxoutWindowEncoder.v2',\n",
       "    'width': 64,\n",
       "    'window_size': 1,\n",
       "    'maxout_pieces': 3,\n",
       "    'depth': 2}}},\n",
       " 'scorer': {'@scorers': 'spacy.textcat_scorer.v2'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_config = nlp.get_pipe_meta(\"textcat\").default_config\n",
    "default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c2a70-fb8e-47c5-a2df-e7d4e8f0b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "# apply the spacy model to the training data\n",
    "processed_docs = [nlp(text) for text in train.Text]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5b0365-121d-48be-8935-219df18fce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': {'train': 'null',\n",
       "  'dev': 'null',\n",
       "  'vectors': 'null',\n",
       "  'init_tok2vec': 'null'},\n",
       " 'system': {'gpu_allocator': 'null', 'seed': '0'},\n",
       " 'nlp': {'lang': '\"en\"',\n",
       "  'pipeline': '[\"textcat\"]',\n",
       "  'batch_size': '1000',\n",
       "  'disabled': '[]',\n",
       "  'before_creation': 'null',\n",
       "  'after_creation': 'null',\n",
       "  'after_pipeline_creation': 'null',\n",
       "  'tokenizer': '{\"@tokenizers\":\"spacy.Tokenizer.v1\"}',\n",
       "  'vectors': '{\"@vectors\":\"spacy.Vectors.v1\"}'},\n",
       " 'components': {},\n",
       " 'components.textcat': {'factory': '\"textcat\"',\n",
       "  'scorer': '{\"@scorers\":\"spacy.textcat_scorer.v2\"}',\n",
       "  'threshold': '0.0'},\n",
       " 'components.textcat.model': {'@architectures': '\"spacy.TextCatBOW.v2\"',\n",
       "  'exclusive_classes': 'true',\n",
       "  'ngram_size': '1',\n",
       "  'no_output_layer': 'false',\n",
       "  'no': 'null'},\n",
       " 'corpora': {},\n",
       " 'corpora.dev': {'@readers': '\"spacy.Corpus.v1\"',\n",
       "  'path': '${paths.dev}',\n",
       "  'max_length': '0',\n",
       "  'gold_preproc': 'false',\n",
       "  'limit': '0',\n",
       "  'augmenter': 'null'},\n",
       " 'corpora.train': {'@readers': '\"spacy.Corpus.v1\"',\n",
       "  'path': '${paths.train}',\n",
       "  'max_length': '0',\n",
       "  'gold_preproc': 'false',\n",
       "  'limit': '0',\n",
       "  'augmenter': 'null'},\n",
       " 'training': {'dev_corpus': '\"corpora.dev\"',\n",
       "  'train_corpus': '\"corpora.train\"',\n",
       "  'seed': '${system.seed}',\n",
       "  'gpu_allocator': '${system.gpu_allocator}',\n",
       "  'dropout': '0.1',\n",
       "  'accumulate_gradient': '1',\n",
       "  'patience': '1600',\n",
       "  'max_epochs': '0',\n",
       "  'max_steps': '20000',\n",
       "  'eval_frequency': '200',\n",
       "  'frozen_components': '[]',\n",
       "  'annotating_components': '[]',\n",
       "  'before_to_disk': 'null',\n",
       "  'before_update': 'null'},\n",
       " 'training.batcher': {'@batchers': '\"spacy.batch_by_words.v1\"',\n",
       "  'discard_oversize': 'false',\n",
       "  'tolerance': '0.2',\n",
       "  'get_length': 'null'},\n",
       " 'training.batcher.size': {'@schedules': '\"compounding.v1\"',\n",
       "  'start': '100',\n",
       "  'stop': '1000',\n",
       "  'compound': '1.001',\n",
       "  't': '0.0'},\n",
       " 'training.logger': {'@loggers': '\"spacy.ConsoleLogger.v1\"',\n",
       "  'progress_bar': 'false'},\n",
       " 'training.optimizer': {'@optimizers': '\"Adam.v1\"',\n",
       "  'beta1': '0.9',\n",
       "  'beta2': '0.999',\n",
       "  'l2_is_weight_decay': 'true',\n",
       "  'l2': '0.01',\n",
       "  'grad_clip': '1.0',\n",
       "  'use_averages': 'false',\n",
       "  'eps': '0.00000001',\n",
       "  'learn_rate': '0.001'},\n",
       " 'training.score_weights': {'cats_score': '1.0',\n",
       "  'cats_score_desc': 'null',\n",
       "  'cats_micro_p': 'null',\n",
       "  'cats_micro_r': 'null',\n",
       "  'cats_micro_f': 'null',\n",
       "  'cats_macro_p': 'null',\n",
       "  'cats_macro_r': 'null',\n",
       "  'cats_macro_f': 'null',\n",
       "  'cats_macro_auc': 'null',\n",
       "  'cats_f_per_type': 'null'},\n",
       " 'pretraining': {},\n",
       " 'initialize': {'vectors': '${paths.vectors}',\n",
       "  'init_tok2vec': '${paths.init_tok2vec}',\n",
       "  'vocab_data': 'null',\n",
       "  'lookups': 'null',\n",
       "  'before_init': 'null',\n",
       "  'after_init': 'null'},\n",
       " 'initialize.components': {},\n",
       " 'initialize.tokenizer': {}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "def read_spacy_config(file_path):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(file_path)\n",
    "\n",
    "    config_dict = {}\n",
    "    for section in config.sections():\n",
    "        config_dict[section] = {}\n",
    "        for option in config.options(section):\n",
    "            config_dict[section][option] = config.get(section, option)\n",
    "\n",
    "    return config_dict\n",
    "\n",
    "file_path = './inputs/efficiency_cpu_config.cfg'\n",
    "textcat_config = read_spacy_config(file_path)\n",
    "textcat_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fd294-fa02-4ec1-9fd8-daa66e9e3e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb5191-73d3-4665-98fc-d7b5ce0f3a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc508e2-59da-4928-86ad-a383d41de839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nlp",
   "language": "python",
   "name": "pytorch-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
