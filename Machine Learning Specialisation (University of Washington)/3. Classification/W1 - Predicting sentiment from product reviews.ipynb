{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use dataframes to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \n",
       "0       These flannel wipes are OK, but in my opinion ...       3  \n",
       "1       it came early and was not disappointed. i love...       5  \n",
       "2       Very soft and comfortable and warmer than it l...       5  \n",
       "3       This is a product well worth the purchase.  I ...       5  \n",
       "4       All of my kids have cried non-stop when I trie...       5  \n",
       "...                                                   ...     ...  \n",
       "183526  Such a great idea! very handy to have and look...       5  \n",
       "183527  This product rocks!  It is a great blend of fu...       5  \n",
       "183528  This item looks great and cool for my kids.......       5  \n",
       "183529  I am extremely happy with this product. I have...       5  \n",
       "183530  I love this product very mush . I have bought ...       5  \n",
       "\n",
       "[183531 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "\n",
    "Let us explore a specific example of a baby product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      The First Years Massaging Action Teether\n",
       "review                    A favorite in our house!\n",
       "rating                                           5\n",
       "Name: 269, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.iloc[269, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuation for the sake of simplicity. A smarter approach would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in the review column\n",
    "products = products.fillna({'review':''})\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = text.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "products['review_clean'] = products['review'].apply(lambda x: remove_punctuation(x) if x != '' else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK but in my opinion n...</td>\n",
       "      <td>{'these': 1, 'flannel': 1, 'wipes': 3, 'are': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>{'it': 3, 'came': 1, 'early': 1, 'and': 3, 'wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>{'very': 1, 'soft': 1, 'and': 2, 'comfortable'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>{'this': 4, 'is': 4, 'a': 2, 'product': 2, 'we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>{'all': 2, 'of': 1, 'my': 1, 'kids': 2, 'have'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  These flannel wipes are OK, but in my opinion ...       3   \n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  These flannel wipes are OK but in my opinion n...   \n",
       "1  it came early and was not disappointed i love ...   \n",
       "2  Very soft and comfortable and warmer than it l...   \n",
       "3  This is a product well worth the purchase  I h...   \n",
       "4  All of my kids have cried nonstop when I tried...   \n",
       "\n",
       "                                          word_count  \n",
       "0  {'these': 1, 'flannel': 1, 'wipes': 3, 'are': ...  \n",
       "1  {'it': 3, 'came': 1, 'early': 1, 'and': 3, 'wa...  \n",
       "2  {'very': 1, 'soft': 1, 'and': 2, 'comfortable'...  \n",
       "3  {'this': 4, 'is': 4, 'a': 2, 'product': 2, 'we...  \n",
       "4  {'all': 2, 'of': 1, 'my': 1, 'kids': 2, 'have'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['word_count'] = products.review_clean.apply(lambda x: Counter(word.lower() for word in x.split())\n",
    "                                                        if x != '' else {})\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1, 'favorite': 1, 'in': 1, 'our': 1, 'house': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.loc[269, 'word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sentiment\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166752"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products.rating != 3]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>{'it': 3, 'came': 1, 'early': 1, 'and': 3, 'wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>{'very': 1, 'soft': 1, 'and': 2, 'comfortable'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>{'this': 4, 'is': 4, 'a': 2, 'product': 2, 'we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>{'all': 2, 'of': 1, 'my': 1, 'kids': 2, 'have'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>{'when': 2, 'the': 6, 'binky': 3, 'fairy': 3, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  \\\n",
       "1  it came early and was not disappointed i love ...   \n",
       "2  Very soft and comfortable and warmer than it l...   \n",
       "3  This is a product well worth the purchase  I h...   \n",
       "4  All of my kids have cried nonstop when I tried...   \n",
       "5  When the Binky Fairy came to our house we didn...   \n",
       "\n",
       "                                          word_count  sentiment  \n",
       "1  {'it': 3, 'came': 1, 'early': 1, 'and': 3, 'wa...          1  \n",
       "2  {'very': 1, 'soft': 1, 'and': 2, 'comfortable'...          1  \n",
       "3  {'this': 4, 'is': 4, 'a': 2, 'product': 2, 'we...          1  \n",
       "4  {'all': 2, 'of': 1, 'my': 1, 'kids': 2, 'have'...          1  \n",
       "5  {'when': 2, 'the': 6, 'binky': 3, 'fairy': 3, ...          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products.rating.apply(lambda rating: +1 if rating > 3 else -1)\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = products.random_split(0.8, seed=1)\n",
    "# print(len(train_data))\n",
    "# print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the correct results for the quiz, you need to read in a list of train and test indices from a set of json files instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416\n",
      "33336\n"
     ]
    }
   ],
   "source": [
    "with open('W1-assignment-train-idx.json', 'r') as f:\n",
    "    test_indices = json.load(f)\n",
    "train_data = products.iloc[test_indices]\n",
    "\n",
    "with open('W1-assignment-test-idx.json', 'r') as f:\n",
    "    test_indices = json.load(f)\n",
    "test_data = products.iloc[test_indices]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. General steps for extracting word count vectors are as follows:\n",
    "- Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "- Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "- Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "- Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix.\n",
    "\n",
    "Keep in mind that the test data must be transformed in the same way as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this token pattern to keep single-letter words\n",
    "vectoriser = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# first, learn vocabulary from the training data and assign columns to words\n",
    "# then convert the training data into a sparse matrix\n",
    "train_matrix = vectoriser.fit_transform(train_data.review_clean)\n",
    "# second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectoriser.transform(test_data.review_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = LogisticRegression(solver='liblinear')\n",
    "sentiment_model.fit(train_matrix, train_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of `121713` coefficients in the model (`121712` plus the intercept). Recall from the lecture that positive weights $w_j$ correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (>= 0, which is actually nonnegative) coefficients.\n",
    "\n",
    "Now that we have fitted the model, we can extract the weights (coefficients):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.23995580e+00  2.73385478e-05  2.75426081e-02 ...  1.26133766e-02\n",
      "   2.70133082e-03 -4.12496602e-05]]\n",
      "(1, 121712)\n"
     ]
    }
   ],
   "source": [
    "weights = sentiment_model.coef_\n",
    "print(weights)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 87104 \n",
      "Number of negative weights: 34608 \n"
     ]
    }
   ],
   "source": [
    "num_positive_weights = np.count_nonzero(weights >= 0)\n",
    "num_negative_weights = np.count_nonzero(weights < 0)\n",
    "\n",
    "print(\"Number of positive weights: %s \" % num_positive_weights)\n",
    "print(\"Number of negative weights: %s \" % num_negative_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>{'absolutely': 1, 'love': 1, 'it': 2, 'and': 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Wall Decor Removable Decal Sticker - Colorful ...</td>\n",
       "      <td>Would not purchase again or recommend. The dec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Would not purchase again or recommend The deca...</td>\n",
       "      <td>{'would': 2, 'not': 2, 'purchase': 1, 'again':...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>New Style Trailing Cherry Blossom Tree Decal R...</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>1</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>{'was': 2, 'so': 1, 'excited': 1, 'to': 3, 'ge...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "59                          Our Baby Girl Memory Book   \n",
       "71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
       "91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "59  Absolutely love it and all of the Scripture in...       5   \n",
       "71  Would not purchase again or recommend. The dec...       2   \n",
       "91  Was so excited to get this product for my baby...       1   \n",
       "\n",
       "                                         review_clean  \\\n",
       "59  Absolutely love it and all of the Scripture in...   \n",
       "71  Would not purchase again or recommend The deca...   \n",
       "91  Was so excited to get this product for my baby...   \n",
       "\n",
       "                                           word_count  sentiment  \n",
       "59  {'absolutely': 1, 'love': 1, 'it': 2, 'and': 2...          1  \n",
       "71  {'would': 2, 'not': 2, 'purchase': 1, 'again':...         -1  \n",
       "91  {'was': 2, 'so': 1, 'excited': 1, 'to': 3, 'ge...         -1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data.iloc[10:13, :]\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[1]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  For each row, the **score** (or margin) is a number in the range **(-inf, inf)**. Use a pre-built function to calculate the score of each data point in **sample_test_data**. In scikit-learn, you can call the decision_function() function.\n",
    "\n",
    "**Hint**: You probably need to convert sample_test_data into the sparse matrix format first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60159415  -3.16903527 -10.42328687]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectoriser.transform(sample_test_data.review_clean)\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y_i} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions for sample_test_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "preds = [1 if score > 0 else -1 for score in scores]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to verify that the class predictions obtained by your calculations are the same as that obtained from Turi Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to sklearn:\n",
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class predictions according to sklearn:\")\n",
    "print(sentiment_model.predict(sample_test_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the ones obtained from **sentiment_model**. The logistic regression classifier in scikit-learn comes with the **predict** function for this purpose.\n",
    "\n",
    "### Probability predictions\n",
    "\n",
    "We can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9963216070625329, 0.04034775288486938, 2.973110961576348e-05]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = [1/(1+math.exp(-score)) for score in scores]\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from Turi Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class probabilities according to sklearn:\n",
      "[9.96321607e-01 4.03477529e-02 2.97311096e-05]\n"
     ]
    }
   ],
   "source": [
    "print(\"Class probabilities according to sklearn:\")\n",
    "print(sentiment_model.predict_proba(sample_test_matrix)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review? The third one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the most positive (and negative) review\n",
    "\n",
    "We now turn to examining the full test dataset, **test_data**, and use sklearn.linear_model.LogisticRegression to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`.\n",
    "2.  Sort the data according to those predictions and pick the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100166</th>\n",
       "      <td>Infantino Wrap and Tie Baby Carrier, Black Blu...</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>{'i': 28, 'bought': 1, 'this': 6, 'carrier': 7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66059</th>\n",
       "      <td>Evenflo 6 Pack Classic Glass Bottle, 4-Ounce</td>\n",
       "      <td>It's always fun to write a review on those pro...</td>\n",
       "      <td>5</td>\n",
       "      <td>Its always fun to write a review on those prod...</td>\n",
       "      <td>{'its': 2, 'always': 3, 'fun': 1, 'to': 23, 'w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97325</th>\n",
       "      <td>Freemie Hands-Free Concealable Breast Pump Col...</td>\n",
       "      <td>I absolutely love this product.  I work as a C...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love this product  I work as a Cu...</td>\n",
       "      <td>{'i': 38, 'absolutely': 1, 'love': 1, 'this': ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22586</th>\n",
       "      <td>Britax Decathlon Convertible Car Seat, Tiffany</td>\n",
       "      <td>I researched a few different seats to put in o...</td>\n",
       "      <td>4</td>\n",
       "      <td>I researched a few different seats to put in o...</td>\n",
       "      <td>{'i': 26, 'researched': 2, 'a': 22, 'few': 3, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140816</th>\n",
       "      <td>Diono RadianRXT Convertible Car Seat, Plum</td>\n",
       "      <td>I bought this seat for my tall (38in) and thin...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this seat for my tall 38in and thin 2...</td>\n",
       "      <td>{'i': 23, 'bought': 1, 'this': 11, 'seat': 22,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114796</th>\n",
       "      <td>Fisher-Price Cradle 'N Swing,  My Little Snuga...</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>{'my': 1, 'husband': 1, 'and': 19, 'i': 3, 'ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137034</th>\n",
       "      <td>Graco Pack 'n Play Element Playard - Flint</td>\n",
       "      <td>My husband and I assembled this Pack n' Play l...</td>\n",
       "      <td>4</td>\n",
       "      <td>My husband and I assembled this Pack n Play la...</td>\n",
       "      <td>{'my': 2, 'husband': 2, 'and': 13, 'i': 8, 'as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168697</th>\n",
       "      <td>Graco FastAction Fold Jogger Click Connect Str...</td>\n",
       "      <td>Graco's FastAction Jogging Stroller definitely...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gracos FastAction Jogging Stroller definitely ...</td>\n",
       "      <td>{'gracos': 1, 'fastaction': 2, 'jogging': 2, '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119182</th>\n",
       "      <td>Roan Rocco Classic Pram Stroller 2-in-1 with B...</td>\n",
       "      <td>Great Pram Rocco!!!!!!I bought this pram from ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Pram RoccoI bought this pram from Europe...</td>\n",
       "      <td>{'great': 4, 'pram': 10, 'roccoi': 1, 'bought'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168081</th>\n",
       "      <td>Buttons Cloth Diaper Cover - One Size - 8 Colo...</td>\n",
       "      <td>We are big Best Bottoms fans here, but I wante...</td>\n",
       "      <td>4</td>\n",
       "      <td>We are big Best Bottoms fans here but I wanted...</td>\n",
       "      <td>{'we': 3, 'are': 6, 'big': 2, 'best': 13, 'bot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133651</th>\n",
       "      <td>Britax 2012 B-Agile Stroller, Red</td>\n",
       "      <td>[I got this stroller for my daughter prior to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>I got this stroller for my daughter prior to t...</td>\n",
       "      <td>{'i': 22, 'got': 3, 'this': 17, 'stroller': 22...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50315</th>\n",
       "      <td>P'Kolino Silly Soft Seating in Tias, Green</td>\n",
       "      <td>I've purchased both the P'Kolino Little Reader...</td>\n",
       "      <td>4</td>\n",
       "      <td>Ive purchased both the PKolino Little Reader C...</td>\n",
       "      <td>{'ive': 1, 'purchased': 1, 'both': 3, 'the': 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87017</th>\n",
       "      <td>Baby Einstein Around The World Discovery Center</td>\n",
       "      <td>I am so HAPPY I brought this item for my 7 mon...</td>\n",
       "      <td>5</td>\n",
       "      <td>I am so HAPPY I brought this item for my 7 mon...</td>\n",
       "      <td>{'i': 23, 'am': 1, 'so': 3, 'happy': 1, 'broug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180646</th>\n",
       "      <td>Mamas &amp;amp; Papas 2014 Urbo2 Stroller - Black</td>\n",
       "      <td>After much research I purchased an Urbo2. It's...</td>\n",
       "      <td>4</td>\n",
       "      <td>After much research I purchased an Urbo2 Its e...</td>\n",
       "      <td>{'after': 1, 'much': 3, 'research': 1, 'i': 17...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52631</th>\n",
       "      <td>Evenflo X Sport Plus Convenience Stroller - Ch...</td>\n",
       "      <td>After seeing this in Parent's Magazine and rea...</td>\n",
       "      <td>5</td>\n",
       "      <td>After seeing this in Parents Magazine and read...</td>\n",
       "      <td>{'after': 2, 'seeing': 1, 'this': 12, 'in': 6,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80155</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>I just tried this hands free breastpump bra, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>I just tried this hands free breastpump bra an...</td>\n",
       "      <td>{'i': 23, 'just': 4, 'tried': 2, 'this': 4, 'h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147949</th>\n",
       "      <td>Baby Jogger City Mini GT Single Stroller, Shad...</td>\n",
       "      <td>Amazing, Love, Love, Love it !!! All 5 STARS a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing Love Love Love it  All 5 STARS all the...</td>\n",
       "      <td>{'amazing': 1, 'love': 4, 'it': 7, 'all': 3, '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165593</th>\n",
       "      <td>Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...</td>\n",
       "      <td>For the price this set is unbelievable- and tr...</td>\n",
       "      <td>5</td>\n",
       "      <td>For the price this set is unbelievable and tru...</td>\n",
       "      <td>{'for': 15, 'the': 19, 'price': 1, 'this': 2, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182089</th>\n",
       "      <td>Summer Infant Wide View Digital Color Video Mo...</td>\n",
       "      <td>I love this baby monitor.  I can compare this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this baby monitor  I can compare this o...</td>\n",
       "      <td>{'i': 17, 'love': 2, 'this': 20, 'baby': 12, '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147996</th>\n",
       "      <td>Baby Jogger City Mini GT Double Stroller, Shad...</td>\n",
       "      <td>We are well pleased with this stroller, and I ...</td>\n",
       "      <td>4</td>\n",
       "      <td>We are well pleased with this stroller and I w...</td>\n",
       "      <td>{'we': 2, 'are': 2, 'well': 4, 'pleased': 1, '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "100166  Infantino Wrap and Tie Baby Carrier, Black Blu...   \n",
       "66059        Evenflo 6 Pack Classic Glass Bottle, 4-Ounce   \n",
       "97325   Freemie Hands-Free Concealable Breast Pump Col...   \n",
       "22586      Britax Decathlon Convertible Car Seat, Tiffany   \n",
       "140816         Diono RadianRXT Convertible Car Seat, Plum   \n",
       "114796  Fisher-Price Cradle 'N Swing,  My Little Snuga...   \n",
       "137034         Graco Pack 'n Play Element Playard - Flint   \n",
       "168697  Graco FastAction Fold Jogger Click Connect Str...   \n",
       "119182  Roan Rocco Classic Pram Stroller 2-in-1 with B...   \n",
       "168081  Buttons Cloth Diaper Cover - One Size - 8 Colo...   \n",
       "133651                  Britax 2012 B-Agile Stroller, Red   \n",
       "50315          P'Kolino Silly Soft Seating in Tias, Green   \n",
       "87017     Baby Einstein Around The World Discovery Center   \n",
       "180646      Mamas &amp; Papas 2014 Urbo2 Stroller - Black   \n",
       "52631   Evenflo X Sport Plus Convenience Stroller - Ch...   \n",
       "80155   Simple Wishes Hands-Free Breastpump Bra, Pink,...   \n",
       "147949  Baby Jogger City Mini GT Single Stroller, Shad...   \n",
       "165593  Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...   \n",
       "182089  Summer Infant Wide View Digital Color Video Mo...   \n",
       "147996  Baby Jogger City Mini GT Double Stroller, Shad...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "100166  I bought this carrier when my daughter was abo...       5   \n",
       "66059   It's always fun to write a review on those pro...       5   \n",
       "97325   I absolutely love this product.  I work as a C...       5   \n",
       "22586   I researched a few different seats to put in o...       4   \n",
       "140816  I bought this seat for my tall (38in) and thin...       5   \n",
       "114796  My husband and I cannot state enough how much ...       5   \n",
       "137034  My husband and I assembled this Pack n' Play l...       4   \n",
       "168697  Graco's FastAction Jogging Stroller definitely...       5   \n",
       "119182  Great Pram Rocco!!!!!!I bought this pram from ...       5   \n",
       "168081  We are big Best Bottoms fans here, but I wante...       4   \n",
       "133651  [I got this stroller for my daughter prior to ...       4   \n",
       "50315   I've purchased both the P'Kolino Little Reader...       4   \n",
       "87017   I am so HAPPY I brought this item for my 7 mon...       5   \n",
       "180646  After much research I purchased an Urbo2. It's...       4   \n",
       "52631   After seeing this in Parent's Magazine and rea...       5   \n",
       "80155   I just tried this hands free breastpump bra, a...       5   \n",
       "147949  Amazing, Love, Love, Love it !!! All 5 STARS a...       5   \n",
       "165593  For the price this set is unbelievable- and tr...       5   \n",
       "182089  I love this baby monitor.  I can compare this ...       5   \n",
       "147996  We are well pleased with this stroller, and I ...       4   \n",
       "\n",
       "                                             review_clean  \\\n",
       "100166  I bought this carrier when my daughter was abo...   \n",
       "66059   Its always fun to write a review on those prod...   \n",
       "97325   I absolutely love this product  I work as a Cu...   \n",
       "22586   I researched a few different seats to put in o...   \n",
       "140816  I bought this seat for my tall 38in and thin 2...   \n",
       "114796  My husband and I cannot state enough how much ...   \n",
       "137034  My husband and I assembled this Pack n Play la...   \n",
       "168697  Gracos FastAction Jogging Stroller definitely ...   \n",
       "119182  Great Pram RoccoI bought this pram from Europe...   \n",
       "168081  We are big Best Bottoms fans here but I wanted...   \n",
       "133651  I got this stroller for my daughter prior to t...   \n",
       "50315   Ive purchased both the PKolino Little Reader C...   \n",
       "87017   I am so HAPPY I brought this item for my 7 mon...   \n",
       "180646  After much research I purchased an Urbo2 Its e...   \n",
       "52631   After seeing this in Parents Magazine and read...   \n",
       "80155   I just tried this hands free breastpump bra an...   \n",
       "147949  Amazing Love Love Love it  All 5 STARS all the...   \n",
       "165593  For the price this set is unbelievable and tru...   \n",
       "182089  I love this baby monitor  I can compare this o...   \n",
       "147996  We are well pleased with this stroller and I w...   \n",
       "\n",
       "                                               word_count  sentiment  \n",
       "100166  {'i': 28, 'bought': 1, 'this': 6, 'carrier': 7...          1  \n",
       "66059   {'its': 2, 'always': 3, 'fun': 1, 'to': 23, 'w...          1  \n",
       "97325   {'i': 38, 'absolutely': 1, 'love': 1, 'this': ...          1  \n",
       "22586   {'i': 26, 'researched': 2, 'a': 22, 'few': 3, ...          1  \n",
       "140816  {'i': 23, 'bought': 1, 'this': 11, 'seat': 22,...          1  \n",
       "114796  {'my': 1, 'husband': 1, 'and': 19, 'i': 3, 'ca...          1  \n",
       "137034  {'my': 2, 'husband': 2, 'and': 13, 'i': 8, 'as...          1  \n",
       "168697  {'gracos': 1, 'fastaction': 2, 'jogging': 2, '...          1  \n",
       "119182  {'great': 4, 'pram': 10, 'roccoi': 1, 'bought'...          1  \n",
       "168081  {'we': 3, 'are': 6, 'big': 2, 'best': 13, 'bot...          1  \n",
       "133651  {'i': 22, 'got': 3, 'this': 17, 'stroller': 22...          1  \n",
       "50315   {'ive': 1, 'purchased': 1, 'both': 3, 'the': 3...          1  \n",
       "87017   {'i': 23, 'am': 1, 'so': 3, 'happy': 1, 'broug...          1  \n",
       "180646  {'after': 1, 'much': 3, 'research': 1, 'i': 17...          1  \n",
       "52631   {'after': 2, 'seeing': 1, 'this': 12, 'in': 6,...          1  \n",
       "80155   {'i': 23, 'just': 4, 'tried': 2, 'this': 4, 'h...          1  \n",
       "147949  {'amazing': 1, 'love': 4, 'it': 7, 'all': 3, '...          1  \n",
       "165593  {'for': 15, 'the': 19, 'price': 1, 'this': 2, ...          1  \n",
       "182089  {'i': 17, 'love': 2, 'this': 20, 'baby': 12, '...          1  \n",
       "147996  {'we': 2, 'are': 2, 'well': 4, 'pleased': 1, '...          1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = sentiment_model.predict_proba(test_matrix)[:, 1]\n",
    "top_positive_idx = np.argsort(-probs)[:20]\n",
    "most_positive = test_data.iloc[top_positive_idx]\n",
    "most_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Baby Einstein Around The World Discovery Center',\n",
       "       'Baby Jogger City Mini GT Double Stroller, Shadow/Orange',\n",
       "       'Baby Jogger City Mini GT Single Stroller, Shadow/Orange',\n",
       "       'Britax 2012 B-Agile Stroller, Red',\n",
       "       'Britax Decathlon Convertible Car Seat, Tiffany',\n",
       "       'Buttons Cloth Diaper Cover - One Size - 8 Color Options',\n",
       "       'Diono RadianRXT Convertible Car Seat, Plum',\n",
       "       'Evenflo 6 Pack Classic Glass Bottle, 4-Ounce',\n",
       "       'Evenflo X Sport Plus Convenience Stroller - Christina',\n",
       "       \"Fisher-Price Cradle 'N Swing,  My Little Snugabunny\",\n",
       "       'Freemie Hands-Free Concealable Breast Pump Collection System',\n",
       "       'Graco FastAction Fold Jogger Click Connect Stroller, Grapeade',\n",
       "       \"Graco Pack 'n Play Element Playard - Flint\",\n",
       "       'Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatware, Bowl, Plate, Tumbler Set, Colorful',\n",
       "       'Infantino Wrap and Tie Baby Carrier, Black Blueberries',\n",
       "       'Mamas &amp; Papas 2014 Urbo2 Stroller - Black',\n",
       "       \"P'Kolino Silly Soft Seating in Tias, Green\",\n",
       "       'Roan Rocco Classic Pram Stroller 2-in-1 with Bassinet and Seat Unit - Coffee',\n",
       "       'Simple Wishes Hands-Free Breastpump Bra, Pink, XS-L',\n",
       "       'Summer Infant Wide View Digital Color Video Monitor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_products = np.unique(most_positive.name)\n",
    "positive_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>We have not had ANY luck with Fisher-Price pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>We have not had ANY luck with FisherPrice prod...</td>\n",
       "      <td>{'we': 3, 'have': 3, 'not': 5, 'had': 1, 'any'...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120209</th>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>{'this': 9, 'is': 7, 'the': 21, 'first': 3, 'r...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>{'i': 18, 'thought': 1, 'it': 8, 'sounded': 1,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>{'i': 26, 'will': 4, 'try': 2, 'to': 29, 'writ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>{'this': 12, 'is': 15, 'my': 6, 'second': 3, '...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94560</th>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "      <td>Note: we never installed batteries in these un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Note we never installed batteries in these uni...</td>\n",
       "      <td>{'note': 1, 'we': 3, 'never': 1, 'installed': ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53207</th>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>{'we': 1, 'bought': 1, 'this': 5, 'baby': 8, '...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81332</th>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>{'i': 12, 'bought': 1, 'this': 3, 'sprayer': 2...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "      <td>It's 3am in the morning and needless to say, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Its 3am in the morning and needless to say thi...</td>\n",
       "      <td>{'its': 1, '3am': 3, 'in': 2, 'the': 11, 'morn...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>{'do': 1, 'not': 2, 'buy': 1, 'this': 6, 'baby...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59546</th>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>{'this': 4, 'is': 4, 'basically': 2, 'an': 1, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>{'i': 9, 'bought': 1, 'this': 13, 'car': 11, '...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40079</th>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>{'my': 3, 'wife': 1, 'and': 9, 'i': 7, 'have':...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172090</th>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>2</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>{'i': 15, 'read': 1, 'so': 3, 'many': 1, 'revi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75994</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>2</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>{'i': 20, 'can': 3, 'see': 2, 'why': 1, 'there...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149987</th>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "      <td>It thought this would be great. I did a lot of...</td>\n",
       "      <td>1</td>\n",
       "      <td>It thought this would be great I did a lot of ...</td>\n",
       "      <td>{'it': 8, 'thought': 2, 'this': 3, 'would': 5,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154878</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "      <td>First, the distance on these are no more than ...</td>\n",
       "      <td>1</td>\n",
       "      <td>First the distance on these are no more than 7...</td>\n",
       "      <td>{'first': 2, 'the': 16, 'distance': 1, 'on': 9...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>{'this': 3, 'item': 1, 'is': 2, 'junk': 2, 'i'...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>{'if': 3, 'i': 14, 'could': 1, 'give': 1, 'thi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83234</th>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "      <td>My Experience: Babykicks Inserts failure vs RA...</td>\n",
       "      <td>5</td>\n",
       "      <td>My Experience Babykicks Inserts failure vs RAV...</td>\n",
       "      <td>{'my': 2, 'experience': 1, 'babykicks': 16, 'i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "16042         Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "120209  Levana Safe N'See Digital Video Baby Monitor w...   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "94560   The First Years True Choice P400 Premium Digit...   \n",
       "53207                 Safety 1st High-Def Digital Monitor   \n",
       "81332               Cloth Diaper Sprayer--styles may vary   \n",
       "10677                   Philips AVENT Newborn Starter Set   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "59546              Ellaroo Mei Tai Baby Carrier - Hershey   \n",
       "9915         Cosco Alpha Omega Elite Convertible Car Seat   \n",
       "40079   Chicco Cortina KeyFit 30 Travel System in Adve...   \n",
       "172090  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...   \n",
       "75994          Peg-Perego Tatamia High Chair, White Latte   \n",
       "149987                   NUK Cook-n-Blend Baby Food Maker   \n",
       "154878  VTech Communications Safe &amp; Sound Digital ...   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "31741              Regalo My Cot Portable Bed, Royal Blue   \n",
       "83234       Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "16042   We have not had ANY luck with Fisher-Price pro...       2   \n",
       "120209  This is the first review I have ever written o...       1   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "94560   Note: we never installed batteries in these un...       1   \n",
       "53207   We bought this baby monitor to replace a diffe...       1   \n",
       "81332   I bought this sprayer out of desperation durin...       1   \n",
       "10677   It's 3am in the morning and needless to say, t...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "59546   This is basically an overpriced piece of fabri...       1   \n",
       "9915    I bought this car seat after both seeing  the ...       1   \n",
       "40079   My wife and I have used this system in two car...       1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...       2   \n",
       "75994   I can see why there are so many good reviews o...       2   \n",
       "149987  It thought this would be great. I did a lot of...       1   \n",
       "154878  First, the distance on these are no more than ...       1   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "31741   If I could give this product zero stars I woul...       1   \n",
       "83234   My Experience: Babykicks Inserts failure vs RA...       5   \n",
       "\n",
       "                                             review_clean  \\\n",
       "16042   We have not had ANY luck with FisherPrice prod...   \n",
       "120209  This is the first review I have ever written o...   \n",
       "77072   I thought it sounded great to have different t...   \n",
       "48694   I will try to write an objective review of the...   \n",
       "155287  This is my second video monitoring system the ...   \n",
       "94560   Note we never installed batteries in these uni...   \n",
       "53207   We bought this baby monitor to replace a diffe...   \n",
       "81332   I bought this sprayer out of desperation durin...   \n",
       "10677   Its 3am in the morning and needless to say thi...   \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...   \n",
       "59546   This is basically an overpriced piece of fabri...   \n",
       "9915    I bought this car seat after both seeing  the ...   \n",
       "40079   My wife and I have used this system in two car...   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...   \n",
       "75994   I can see why there are so many good reviews o...   \n",
       "149987  It thought this would be great I did a lot of ...   \n",
       "154878  First the distance on these are no more than 7...   \n",
       "1116    This item is junk  I originally chose it becau...   \n",
       "31741   If I could give this product zero stars I woul...   \n",
       "83234   My Experience Babykicks Inserts failure vs RAV...   \n",
       "\n",
       "                                               word_count  sentiment  \n",
       "16042   {'we': 3, 'have': 3, 'not': 5, 'had': 1, 'any'...         -1  \n",
       "120209  {'this': 9, 'is': 7, 'the': 21, 'first': 3, 'r...         -1  \n",
       "77072   {'i': 18, 'thought': 1, 'it': 8, 'sounded': 1,...         -1  \n",
       "48694   {'i': 26, 'will': 4, 'try': 2, 'to': 29, 'writ...         -1  \n",
       "155287  {'this': 12, 'is': 15, 'my': 6, 'second': 3, '...         -1  \n",
       "94560   {'note': 1, 'we': 3, 'never': 1, 'installed': ...         -1  \n",
       "53207   {'we': 1, 'bought': 1, 'this': 5, 'baby': 8, '...         -1  \n",
       "81332   {'i': 12, 'bought': 1, 'this': 3, 'sprayer': 2...         -1  \n",
       "10677   {'its': 1, '3am': 3, 'in': 2, 'the': 11, 'morn...         -1  \n",
       "113995  {'do': 1, 'not': 2, 'buy': 1, 'this': 6, 'baby...         -1  \n",
       "59546   {'this': 4, 'is': 4, 'basically': 2, 'an': 1, ...         -1  \n",
       "9915    {'i': 9, 'bought': 1, 'this': 13, 'car': 11, '...         -1  \n",
       "40079   {'my': 3, 'wife': 1, 'and': 9, 'i': 7, 'have':...         -1  \n",
       "172090  {'i': 15, 'read': 1, 'so': 3, 'many': 1, 'revi...         -1  \n",
       "75994   {'i': 20, 'can': 3, 'see': 2, 'why': 1, 'there...         -1  \n",
       "149987  {'it': 8, 'thought': 2, 'this': 3, 'would': 5,...         -1  \n",
       "154878  {'first': 2, 'the': 16, 'distance': 1, 'on': 9...         -1  \n",
       "1116    {'this': 3, 'item': 1, 'is': 2, 'junk': 2, 'i'...         -1  \n",
       "31741   {'if': 3, 'i': 14, 'could': 1, 'give': 1, 'thi...         -1  \n",
       "83234   {'my': 2, 'experience': 1, 'babykicks': 16, 'i...          1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_negative_idx = np.argsort(probs)[:20]\n",
    "most_negative = test_data.iloc[top_negative_idx]\n",
    "most_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adiri BPA Free Natural Nurser Ultimate Bottle Stage 1 White, Slow Flow (0-3 months)',\n",
       "       'Belkin WeMo Wi-Fi Baby Monitor for Apple iPhone, iPad, and iPod Touch (Firmware Update)',\n",
       "       'Chicco Cortina KeyFit 30 Travel System in Adventure',\n",
       "       'Cloth Diaper Sprayer--styles may vary',\n",
       "       'Cosco Alpha Omega Elite Convertible Car Seat',\n",
       "       'Ellaroo Mei Tai Baby Carrier - Hershey',\n",
       "       'Fisher-Price Ocean Wonders Aquarium Bouncer',\n",
       "       \"Levana Safe N'See Digital Video Baby Monitor with Talk-to-Baby Intercom and Lullaby Control (LV-TW501)\",\n",
       "       'Motorola Digital Video Baby Monitor with Room Temperature Thermometer',\n",
       "       'NUK Cook-n-Blend Baby Food Maker',\n",
       "       'Peg-Perego Tatamia High Chair, White Latte',\n",
       "       'Philips AVENT Newborn Starter Set',\n",
       "       'Regalo My Cot Portable Bed, Royal Blue',\n",
       "       'Safety 1st Deluxe 4-in-1 Bath Station',\n",
       "       'Safety 1st Exchangeable Tip 3 in 1 Thermometer',\n",
       "       'Safety 1st High-Def Digital Monitor',\n",
       "       'The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit',\n",
       "       'Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs',\n",
       "       'VTech Communications Safe &amp; Sound Digital Audio Monitor with two Parent Units',\n",
       "       'VTech Communications Safe &amp; Sounds Full Color Video and Audio Monitor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_products = np.unique(most_negative.name)\n",
    "negative_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    preds = model.predict(data)\n",
    "    # Compute the number of correctly classified examples\n",
    "    num_correct = np.sum(true_labels == preds)\n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    accuracy = num_correct / len(true_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322654187664987"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_matrix, test_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76). 0.93\n",
    "\n",
    "**Quiz Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better? No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', 'well', 'able', 'car', 'broke', 'less', \n",
    "                     'even', 'waste', 'disappointed', 'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(significant_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The CountVectorizer class has a parameter that lets you limit the choice of words when building word count vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectoriser_word_subset.fit_transform(train_data.review_clean)\n",
    "test_matrix_word_subset = vectoriser_word_subset.transform(test_data.review_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a classifier with **word_count_subset** as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = LogisticRegression(solver='liblinear')\n",
    "simple_model.fit(train_matrix_word_subset, train_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693604511639069"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_matrix_word_subset, test_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_coef_table = pd.DataFrame({'word':significant_words,\n",
    "                                        'coefficient': simple_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.673074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perfect</td>\n",
       "      <td>1.509812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>1.363690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>easy</td>\n",
       "      <td>1.192538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>0.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>0.520186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>0.503760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>0.190909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.085513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>0.058855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>less</td>\n",
       "      <td>-0.209563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product</td>\n",
       "      <td>-0.320556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.362167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>even</td>\n",
       "      <td>-0.511380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.621169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.898031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>broke</td>\n",
       "      <td>-1.651576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>waste</td>\n",
       "      <td>-2.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>return</td>\n",
       "      <td>-2.109331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-2.348298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficient\n",
       "6          loves     1.673074\n",
       "5        perfect     1.509812\n",
       "0           love     1.363690\n",
       "2           easy     1.192538\n",
       "1          great     0.944000\n",
       "4         little     0.520186\n",
       "7           well     0.503760\n",
       "8           able     0.190909\n",
       "3            old     0.085513\n",
       "9            car     0.058855\n",
       "11          less    -0.209563\n",
       "16       product    -0.320556\n",
       "18         would    -0.362167\n",
       "12          even    -0.511380\n",
       "15          work    -0.621169\n",
       "17         money    -0.898031\n",
       "10         broke    -1.651576\n",
       "13         waste    -2.033699\n",
       "19        return    -2.109331\n",
       "14  disappointed    -2.348298"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coef_table.sort_values(by='coefficient', ascending=False, inplace=True)\n",
    "simple_model_coef_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(simple_model_coef_table.coefficient > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**? Most, but not all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coef_table = pd.DataFrame({'word': list(vectoriser.vocabulary_.keys()),\n",
    "                                 'coefficient': sentiment_model.coef_.flatten()})\n",
    "\n",
    "sentiment_model_positive_words = list(model_coef_table.loc[model_coef_table.coefficient > 0, 'word'])\n",
    "positive_significant_words = list(simple_model_coef_table.loc[simple_model_coef_table.coefficient > 0, 'word'])\n",
    "\n",
    "len(set(positive_significant_words).intersection(sentiment_model_positive_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing models\n",
    "\n",
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9684745457816154"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, train_matrix, train_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668225700065959"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, train_matrix_word_subset, train_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set? The full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322654187664987"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(sentiment_model, test_matrix, test_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693604511639069"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classification_accuracy(simple_model, test_matrix_word_subset, test_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set? The full model again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**? The positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112164\n",
      "21252\n"
     ]
    }
   ],
   "source": [
    "num_positive  = (train_data['sentiment'] == +1).sum()\n",
    "num_negative = (train_data['sentiment'] == -1).sum()\n",
    "print(num_positive)\n",
    "print(num_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8427825773938085"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_positive  = (test_data['sentiment'] == +1).sum()\n",
    "accuracy = num_positive / test_data.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)? Yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
